server:
  port: 8050

spring:
  datasource:
    dynamic:
      hikari:
        # 连接测试查询
        connection-test-query: SELECT 1 FROM DUAL
        # 连接最大存活时间.不等于0且小于30秒，会被重置为默认值30分钟.设置应该比mysql设置的超时时间短
        max-lifetime: 540000
        # 只有空闲连接数大于最大连接数且空闲时间超过该值，才会被释放
        idle-timeout: 500000
        # 最小空闲连接，默认值10，小于0或大于maximum-pool-size，都会重置为maximum-pool-size
        minimum-idle: 10
        # 最大连接数，小于等于0会被重置为默认值10；大于零小于1会被重置为minimum-idle的值
        maximum-pool-size: 12
        # 连接超时时间:毫秒，小于250毫秒，否则被重置为默认值30秒
        connection-timeout: 60000
      # 设置默认的数据源或者数据源组,默认值即为master
      primary: master
      datasource:
        # 主库数据源
        master:
          driver-class-name: com.mysql.cj.jdbc.Driver
          url: jdbc:mysql://127.0.0.1:3306/twelvet-fast?allowPublicKeyRetrieval=true&useUnicode=true&characterEncoding=utf8&zeroDateTimeBehavior=convertToNull&useSSL=false&serverTimezone=GMT%2B8
          username: root
          password: 123456
        # 从库数据源
        # slave:
        # username:
        # password:
        # url:
        # driver-class-name:
        # JDBC数据源可以使用注解切换
        shardingSphere:
          driver-class-name: org.apache.shardingsphere.driver.ShardingSphereDriver
          url: jdbc:shardingsphere:classpath:sharding-jdbc.yml
            #  shardingsphere:
            #    # 单机模式
            #    mode:
            #      type: Standalone
            #    props:
            #      sql-show: true
            #    datasource:
            #      names: ds0
            #      ds0:
            #        type: com.alibaba.druid.pool.DruidDataSource
            #        driver-class-name=com: com.mysql.cj.jdbc.Driver
            #        # 初始连接数
            #        initialSize: 5
            #        # 最小连接池数量
            #        minIdle: 10
            #        # 最大连接池数量
            #        maxActive: 20
            #        # 配置获取连接等待超时的时间
            #        maxWait: 60000
            #        # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
            #        timeBetweenEvictionRunsMillis: 60000
            #        # 配置一个连接在池中最小生存的时间，单位是毫秒
            #        minEvictableIdleTimeMillis: 300000
            #        # 配置一个连接在池中最大生存的时间，单位是毫秒
            #        maxEvictableIdleTimeMillis: 900000
            #        # 配置检测连接是否有效
            #        validationQuery: SELECT 1 FROM DUAL
            #        testWhileIdle: true
            #        testOnBorrow: false
            #        testOnReturn: false
            #        url: jdbc:mysql://twelvet-mysql:3306/twelvet-fast?allowPublicKeyRetrieval=true&useUnicode=true&characterEncoding=utf8&zeroDateTimeBehavior=convertToNull&useSSL=false&serverTimezone=GMT%2B8
            #        username: root
            #        password: 123456
            #    rules:
            #      sharding:
            #        tables:
            #          # 配置表分片
            #          sys_login_info:
            #            # 数据节点：数据源$->{0..N}.逻辑表名$->{0..N}
            #            actual-data-nodes: ds0.sys_login_info_$->{0..1}
            # 拆分库策略，也就是什么样子的数据放入放到哪个数据库中。
            #          database-strategy:
            #            standard:
            #              shardingColumn: tenantId  # 分片字段（分片键）
            #              preciseAlgorithmClassName: com.shardingjdbc.shardingjdbcstu.algorithm.TenantShardingAlgorithm
            #          # 拆分库策略，也就是什么样子的数据放入放到哪个数据库中。
            #          database-strategy:
            #            inline:  #inline 行表达时分片策略(核心，必须要掌握)
            #              sharding-column: age    # 分片字段（分片键）
            #              algorithm-expression: ds$->{age % 2} # 分片算法表达式
            # 拆分表策略，也就是什么样子的数据放入放到哪个数据表中。
          # 配置分表规则
#            table-strategy:
#              standard:
#                sharding-column: order_no
#                sharding-algorithm-name: table-mod
#          key-generators:
#            # 此处必须要配置，否则会导致报错，因为shardingsphere-jdbc-core-spring-boot-starter需要加载此项配置，官网的demo例子有错
#            # 分布式序列算法：https://shardingsphere.apache.org/document/current/cn/user-manual/common-config/builtin-algorithm/keygen/
#            snowflake:
#              type: SNOWFLAKE
#              props:
#                # 在单机模式下支持用户自定义配置，如果用户不配置使用默认值为0。
#                # 在集群模式下会由系统自动生成，相同的命名空间下不会生成重复的值。
#                worker-id: 0
#            sharding-algorithms:
#              # 分片算法：https://shardingsphere.apache.org/document/current/cn/user-manual/common-config/builtin-algorithm/sharding/
#              table-mod:
#                # 取模类型分片键的值必须是数字，否则会报错
#                type: MOD
#                props:
#                  sharding-count: 10
#      ds0-slave-rules:
#        ds0:
#          ds0-data-source-name: ds0
#          slave-data-source-names: ds0
#      tables:
#        # 自定义表分库分表规则
#        user:
#          table-strategy:
#            inline:
#              algorithm-expression:
#                user_$->{id % 3}
#              # 使用哪一列用作计算分表策略，我们就使用id
#              sharding-column: id
#          key-generator:
#            # 使用雪花算法
#            type: SNOWFLAKE
#            # 配置主键生成策略，因为多张表了，id不能在配置数据库自增，需要配置主键生成策略，user表主键名称是id
#            column: id
#          # 表名枚举，其中的user是需要分表的表名；ds0.user_$->{0..2} 其中ds0表示数据源名称；user_$->{0..2} 表示从user_0到user_2
#          actual-data-nodes: ds0.user_$->{0..2}

# Mybatis配置
mybatis:
  # 搜索指定包别名
  typeAliasesPackage: com.twelvet.**.domain
  # 配置mapper的扫描，找到所有的mapper.xml映射文件
  mapperLocations: classpath*:mapper/*Mapper.xml
  # Mybatis开启日志打印
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
